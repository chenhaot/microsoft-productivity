%!TEX root = proposal.tex

\section{Approach}

% We focus on synchronous collaboration in this proposal. 
% We consider the following three writing tasks.
% We consider two types of suggestions.

In this section, we introduce the computational approaches to provide suggestions in the collaborative writing process.
We consider two types of suggestions: 1) collaboration suggestions that focuses on improving the work flow;
2) content suggestions that aim to provide direct writing support.

To situate our discussion, we use the slogan writing task as our running example in \secref{sec:workflow} and \ref{sec:content}.
Specifically, we envision writing a slogan that offers a concise, memorable,
and powerful statement that is representative of the object,
organization, or idea that it promotes.
We choose this task because slogans are used in a variety of settings, ranging
from organizing a social movement to promoting a product.
The process of condensing information into a memorable and
informative phrase used to create slogans is common across many human teams both in non-profit organizations and the marketing industry.
We further present alternative writing tasks in \secref{sec:tasks}.


\subsection{Collaboration Suggestion}
\label{sec:workflow}

%\my{I changed the following a bit to make 3.1 and 4.1 more align with each other.}
We first consider suggestions that shape the collaboration process.
A key difference between collaborative writing and individual writing lies in these multi-person collaborations that can lead to dramatically different outcomes
depending on whether the collaborative process is successful.
Therefore, our first thrust is to develop computational methods for offering suggestions to improve the effectiveness of collaboration.
% it is important to think about possible suggestions that computational methods can offer to improve the effectiveness of collaboration.
%Another important advantage of such suggestions is that it is relatively easy to support initial experiments with heuristics. 
% cold start: 
% we can define heuristics to support initial experiments.

We consider three types of suggestions on various aspect of collaboration that a machine can offer:
%We consider the following four types of collaboration suggestions (we also provide simple heuristic algorithms for providing them):


\begin{itemize}[leftmargin=*]
	\item {\bf Flow of collaboration}. Suggestions on how the team should decompose the grand writing task into a sequence of subtasks. Such suggestions can enable the team to address the complex writing task by defining and working on a series of smaller-sized, more manageable tasks, in an organized way. It was shown in~\citet{bernstein2010soylent}, for example, that a well-designed workflow can help guide a group of laypeople to work together and accomplish high-quality text proofreading. 
	\item {\bf Division of labor / Work sharing}. Suggestions on whether and how the team should divide the workload among the team members. 
    While organic discussions might start when multiple individuals work in a space together similar to Office 365 or Google doc,
    it is useful to think about how such discussions affect patterns of contribution.
    For instance, \citet{wang2017users} find that ``some users believe that writing should be a private activity because they do not want to be judged or distracted during the thought process''.
    % \citet{birnholtz2013write} found that participants with more utterances tend to make more minor edits.
    % \my{Why it may be helpful + Reference}
	\item {\bf Pace of Work}. Suggestions on whether adjustment of work pace (e.g., speed up, take a break, etc.) is needed. For example, a suggestion that ask the team to take a break and simply talk to each other/ do something entirely irrelevant to writing may help them mitigate the fatigue and overcome cognitive inertia in the writing process~\citep{dai2015and}.

% \begin{itemize}[leftmargin=*]
%     \item Discussion break. The first type of suggestions that we consider is that we simply encourage the team to talk to each other.
%     Taking such a break may help team members overcome cognitive inertia in the writing process.
%     \chenhao{need to read more references on this}
%     A heuristics to recommend discussion breaks can be that there has been too little or too significance changes in each team member's working board.
%     \chenhao{so we should kind of design an individual working space in addition to the collaborating space.}
%     \item Divide-and-conquer (task assignment discussion).
%     The second type of suggestions asks team members to have meta discussions on how to split the task.
%     Such a discussion allows participants to collaboratively,
%     It remains an open question whether a team can come up with effective divde-and-conquer strategy on their own.
%     We can recommend this suggestion at the beginning of an experiment or when we detect similar effort duplicating in individual working boards.
%     \chenhao{or we can just recommend them to work together all the time.}
%     \item Work sharing. In addition, we can directly encourage team members to work in the collaborative space.
%     Organic discussions might start when multiple individuals work in a space together.
%     This suggestion can be activated when too much time has been spent individually.
%     \item Structured collaboration.
%     Finally, one possible suggestion is to ask the team to work according to pre-designed collaboration process.
%     For instance, we can ask the team to first have a high-level discussion about the goal of writing, i.e., what makes a nice slogan.
%     They can then brainstorm initial ideas for possible materials to include.
%     After working individually to generate candidate slogans, they will work together to rank candidate slogans and refine the wording.
%     Such a suggestion can be offered at the beginning of an experiment.
% 
\end{itemize}

There are many factors that can potentially influence the effectiveness of machine-generated collaboration suggestions on the above aspects. We highlight two of them in this proposal --- {\em what to suggest} (i.e., suggested actions) and {\em when to suggest} (i.e., suggestion timing). On both factors, suggestions can be designed based on simple heuristics (e.g., always suggest a team working on a task of slogan writing to follow the default workflow of idea brainstorming $\rightarrow$ candidate slogan generation $\rightarrow$ rank and wording refine, or always provide a work sharing suggestion when it is observed that team members only work in their individual space and there is no activity in the collaborative space, etc.). More intelligent suggestions that tailor to the needs of different teams and adaptively adjust over time based on the work progress can also be designed if sufficient data is collected to enable the reasoning about most effective suggestion content and timing. We will describe in Section~\ref{sec:exp1} on how behavioral experiments will be conducted to understand the effectiveness of various collaboration suggestions.




%%% Tan's version

%\begin{itemize}
%    \item Discussion break. The first type of suggestions that we consider is that we simply encourage the team to talk to each other.
%    Taking such a break may help team members overcome cognitive inertia in the writing process.
%   \chenhao{need to read more references on this}
%    A heuristics to recommend discussion breaks can be that there has been too little or too significance changes in each team member's working board.
%    \chenhao{so we should kind of design an individual working space in addition to the collaborating space.}
%    \item Divide-and-conquer (task assignment discussion).
%    The second type of suggestions asks team members to have meta discussions on how to split the task.
%    Such a discussion allows participants to collaboratively,
%   It remains an open question whether a team can come up with effective divde-and-conquer strategy on their own.
%    We can recommend this suggestion at the beginning of an experiment or when we detect similar effort duplicating in individual working boards.
%    \chenhao{or we can just recommend them to work together all the time.}
%    \item Work sharing. In addition, we can directly encourage team members to work in the collaborative space.
%    Organic discussions might start when multiple individuals work in a space together.
%    This suggestion can be activated when too much time has been spent individually.
%   \item Structured collaboration.
%    Finally, one possible suggestion is to ask the team to work according to pre-designed collaboration process.
%    For instance, we can ask the team to first have a high-level discussion about the goal of writing, i.e., what makes a nice slogan.
%    They can then brainstorm initial ideas for possible materials to include.
%    After working individually to generate candidate slogans, they will work together to rank candidate slogans and refine the wording.
%    Such a suggestion can be offered at the beginning of an experiment.
%\end{itemize}

% If these suggestions are proven effective, it would be useful to develop more sophisticated computational methods to identify optimal timing to determine when to offer such suggestions in the long run.

\subsection{Content Suggestion}
\label{sec:content}

Based on user interviews in our prior work on slogan writing with individuals, we identify two distinct scenarios where content suggestions are useful.
First, users may run out of ideas or struggle with proposing original ideas in the first place.
Content suggestions at this stage functions as brainstorming sessions.
It follows that the notion of relevant suggestions is intentionally vague and there does not exist {\em the} right word.
We refer to such suggestions as ``{\em brainstorming suggestions}''.
Second, users may find it difficult to identify the most appropriate word in a slogan.
In this case, users already have a concrete idea and look for {\em the} word at a particular location.
We refer to such suggestions as ``{\em wording suggestions}''.

% Compared to full-sentence suggestions, although grammaticality is no longer a concern, these two distinct suggestion modes require different computational models.
Furthermore, as writing a sentence is not the main challenge reported in our prior work, we thus focus on lexical suggestions in this proposal.
First, ``brainstorming suggestions'' poses unique computational challenges from traditional natural language processing systems.
One key difference lies in that useful brainstorming suggestions usually do not frequently cooccur and makes NLP techniques that rely on cooccurring patterns much less effective.
% This idea echoes the benign violation theory in humor \citep{warren_opinion:_2015}: violation in humor does not happen frequently in life and cannot be arbitrary.
Second, ``wording suggestions'' connects with existing work on paraphrasing and lexical semantics in modeling synonyms, however, we need to paraphrase for a certain goal, e.g., being more catchy.
We propose the following 
% three 
components to address these computational challenges.

\para{Relevant data collection.} 
The first component is to collect relevant datasets of high quality.
As is common in 
% most big data
AI research,
these datasets constitute the most important resource for our proposed approach.
We plan to collect the following data sources (these are designed for slogans; adaptation is required for other tasks):
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
  \item Slogan database. To understand what slogan looks like, we will collect slogans from websites of top companies and Twitter profiles.
  A classification task might be useful for achieving this goal.
  \item Cultural references. Successful slogans also require an understanding of our culture. One proxy of culture is through famous quotations on Wikiquotes. We will collect an up-to-date version of Wikiquotes.
  %  and preprocess that into appropriate formats.
  % \item Audience information. As explained in \citet{house_slate}, to win the caption contest, it is important to understand the audience of The New Yorker magazine. Professor Thea Lindquist at University Libraries and the PI have discussed obtaining the New Yorker archival data as part of library resources.
\end{itemize}




\para{``Brainstorming suggestion'' model.}
This is the most technically challenging part of our work.
We propose at least two possible approaches.
First, good brainstorm suggestions look different from normal data.
By comparing cooccurring patterns between Wikiquotes/slogans and a background Wikipedia/newspaper data, we can understand what patterns are relatively common in popular cultural references but are not in general textual data.
However, this approach still requires frequent cooccurrences of good brainstorm suggestions in Wikiquotes/slogans, which limits the power of ``brainstorming''.
To address this concern, our second approach further 
% takes advantage of 
leverage the word definitions in dictionaries and 
% aims to learn 
addresses why two words spark pleasant surprises in Wikiquotes/slogans.
Such an approach 
% can hopefully 
might improve the recall of our computational model.
% These brainstorm suggestions will hopefully open up ideas given queries from the team and spark discussions and new queries.

\para{``Lexical choice suggestion'' model.} The process of identifying the most suitable word echoes the classic question of finding synonyms \citep{turney2008uniform}.
We can use existing techniques such as word embeddings based on our collected datasets.
More importantly, we will experiment with tunable suggestions that allow users to choose between different options such as rhyme and alliteration.
An important challenge lies in identifying the useful dimensions for wording choices, such as provocativity, formality, and trendiness.

\subsection{Writing Tasks}
\label{sec:tasks}

In addition to the slogan writing task, we consider the following two tasks:

\para{Online advertisements for search engines.} 
% Another task is to draft a message for online advertisement.
Although drafting online advertisements is somewhat similar to writing slogans,
participants may find it more approachable given the common exposure.
Another advantage of this task is that the evaluation can be done using metrics such as click-through rates via online platforms.

\para{Wikipedia pages.} Wikipedia is arguably the most successful collaborative writing project online.
Our final task of choice is to ask a small team to create a new Wikipedia page.
Depending on how successful our initial experiment is, we can potentially recruit participants from Wikipedia.
A key advantage of this task is that its direct relevance to a successful platform.
Although writing a complete Wikipedia page is challenging for crowdworkers,
we believe that it is promising given recent success in exploring micro tasks in collaborative writing \citep{teevan2016supporting,salehi2017communicating}.

% \begin{itemize}
%     \item Slogans.
%     \item Online advertisements.
%     \item Wikipedia pages.
% \end{itemize}

% Slogans present a challenge to writers distinct from that
% of writing a story: to generate a concise, memorable,
% and powerful statement that is representative of the object,
% organization, or idea it promotes and matches the intention of
% the authors. Slogans are used in a variety of settings, ranging
% from organizing a social movement to promoting a product.
% The process of condensing information into a memorable and
% informative phrase used to create slogans is paralleled in other
% tasks, such as writing headlines, titling papers, and naming
% products. Therefore, a system that supports slogan writing
% could likely be extended to related tasks that prioritize catchy
% and succinct language.


% For the slogan writing task, participants were asked to write
% a slogan for three distinct scenarios: a food packaging tool,
% the movie Her5, and a social cause that protests animal testing
% for cosmetic products. The prompts included descriptions and
% images, from which the participant had to invent an original
% slogan. Like in the story writing case, the task was either done
% alone or partnered with a machine in the loop. In the MIL
% condition, participants used a web interface (see Figure 4).
% Participants in the solo case worked in a blank Google Doc.
% When writing with the web interface, the writer must provide
% a few keywords and write an initial version of the slogan
% (Figure 4, section a). The writer can then “pull” machine
% suggestions at will (Figure 4, section b). Based on the
% writer’s input, the system suggests alternative slogans (Figure
% 4, section c), and the history of the retrieved suggestions is
% tracked for future reference (Figure 4, section d). The system
% provides at most three suggestions in response to each request.
% The writer’s input is on the left, and machine suggestions are
% on the right, reducing the intrusiveness of the suggestions. A
% demo system is available at http://tremoloop.com.
